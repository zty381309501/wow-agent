{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 加载环境变量\n",
    "load_dotenv()\n",
    "# 从环境变量中读取api_key\n",
    "api_key = os.getenv('ZISHU_API_KEY')\n",
    "base_url = \"http://43.200.7.56:8008/v1\"\n",
    "chat_model = \"glm-4-flash\"\n",
    "emb_model = \"embedding-3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from pydantic import Field  # 导入Field，用于Pydantic模型中定义字段的元数据\n",
    "from llama_index.core.llms import (\n",
    "    CustomLLM,\n",
    "    CompletionResponse,\n",
    "    LLMMetadata,\n",
    ")\n",
    "from llama_index.core.embeddings import BaseEmbedding\n",
    "from llama_index.core.llms.callbacks import llm_completion_callback\n",
    "from typing import List, Any, Generator\n",
    "# 定义OurLLM类，继承自CustomLLM基类\n",
    "class OurLLM(CustomLLM):\n",
    "    api_key: str = Field(default=api_key)\n",
    "    base_url: str = Field(default=base_url)\n",
    "    model_name: str = Field(default=chat_model)\n",
    "    client: OpenAI = Field(default=None, exclude=True)  # 显式声明 client 字段\n",
    "\n",
    "    def __init__(self, api_key: str, base_url: str, model_name: str = chat_model, **data: Any):\n",
    "        super().__init__(**data)\n",
    "        self.api_key = api_key\n",
    "        self.base_url = base_url\n",
    "        self.model_name = model_name\n",
    "        self.client = OpenAI(api_key=self.api_key, base_url=self.base_url)  # 使用传入的api_key和base_url初始化 client 实例\n",
    "\n",
    "    @property\n",
    "    def metadata(self) -> LLMMetadata:\n",
    "        \"\"\"Get LLM metadata.\"\"\"\n",
    "        return LLMMetadata(\n",
    "            model_name=self.model_name,\n",
    "        )\n",
    "\n",
    "    @llm_completion_callback()\n",
    "    def complete(self, prompt: str, **kwargs: Any) -> CompletionResponse:\n",
    "        response = self.client.chat.completions.create(model=self.model_name, messages=[{\"role\": \"user\", \"content\": prompt}])\n",
    "        if hasattr(response, 'choices') and len(response.choices) > 0:\n",
    "            response_text = response.choices[0].message.content\n",
    "            return CompletionResponse(text=response_text)\n",
    "        else:\n",
    "            raise Exception(f\"Unexpected response format: {response}\")\n",
    "\n",
    "    @llm_completion_callback()\n",
    "    def stream_complete(\n",
    "        self, prompt: str, **kwargs: Any\n",
    "    ) -> Generator[CompletionResponse, None, None]:\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model_name,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            stream=True\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            for chunk in response:\n",
    "                chunk_message = chunk.choices[0].delta\n",
    "                if not chunk_message.content:\n",
    "                    continue\n",
    "                content = chunk_message.content\n",
    "                yield CompletionResponse(text=content, delta=content)\n",
    "\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Unexpected response format: {e}\")\n",
    "\n",
    "llm = OurLLM(api_key=api_key, base_url=base_url, model_name=chat_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是一个人工智能助手，名为 ChatGLM，是基于清华大学 KEG 实验室和智谱 AI 公司于 2024 年共同训练的语言模型开发的。我的任务是针对用户的问题和要求提供适当的答复和支持。"
     ]
    }
   ],
   "source": [
    "response = llm.stream_complete(\"你是谁？\")\n",
    "for chunk in response:\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# 获取当前工作目录\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# 假设项目根目录是当前目录的上两级目录\n",
    "project_root = os.path.abspath(os.path.join(current_dir, \"..\", \"..\"))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "# sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\", \"..\")))\n",
    "\n",
    "from llama_index.core.agent import ReActAgent\n",
    "from llama_index.core.tools import FunctionTool\n",
    "\n",
    "\n",
    "def multiply(a: float, b: float) -> float:\n",
    "    \"\"\"Multiply two numbers and returns the product\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "def add(a: float, b: float) -> float:\n",
    "    \"\"\"Add two numbers and returns the sum\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    multiply_tool = FunctionTool.from_defaults(fn=multiply)\n",
    "    add_tool = FunctionTool.from_defaults(fn=add)\n",
    "\n",
    "    # 创建ReActAgent实例\n",
    "    agent = ReActAgent.from_tools([multiply_tool, add_tool], llm=llm, verbose=True)\n",
    "\n",
    "    response = agent.chat(\"20+（2*4）等于多少？使用工具计算每一步\")\n",
    "\n",
    "    print(response)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step dfeee9bf-5dd9-46fc-9ceb-0b62a4c9690b. Step input: 上海天气怎么样?，1+6*56=？\n",
      "\u001b[1;3;38;5;200mThought: The user asked two questions, one about the weather in Shanghai and the other is a calculation question. I need to use the get_weather tool to get the weather information for Shanghai and use the multiply and add tools to calculate the sum.\n",
      "Action: get_weather\n",
      "Action Input: {'city': 'SH'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: -1\n",
      "\u001b[0m> Running step 1129adf1-982d-4dde-a40f-f5fd8d97abdf. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: The weather information for Shanghai is not available. Now, I'll proceed to calculate the sum of 1+6*56 using the add and multiply tools.\n",
      "Action: multiply\n",
      "Action Input: {'a': 6, 'b': 56}\n",
      "\u001b[0m\u001b[1;3;34mObservation: 336\n",
      "\u001b[0m> Running step 9cf0a569-3891-4fa2-a3bc-b72a09e2de40. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: I have already calculated the product of 6 and 56, which is 336. Now I will use the add tool to calculate the sum of 1 and 336.\n",
      "Action: add\n",
      "Action Input: {'a': 1, 'b': 336}\n",
      "\u001b[0m\u001b[1;3;34mObservation: 337\n",
      "\u001b[0m> Running step 8448c8bb-1ac2-452f-bbbd-78e8c951e559. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: 上海的天气信息暂时无法获取，计算结果是1+6*56=337。\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "def get_weather(city: str) -> int:\n",
    "    \"\"\"\n",
    "    Gets the weather temperature of a specified city.\n",
    "\n",
    "    Args:\n",
    "    city (str): The name or abbreviation of the city.\n",
    "\n",
    "    Returns:\n",
    "    int: The temperature of the city. Returns 20 for 'NY' (New York),\n",
    "         30 for 'BJ' (Beijing), and -1 for unknown cities.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert the input city to uppercase to handle case-insensitive comparisons\n",
    "    city = city.upper()\n",
    "\n",
    "    # Check if the city is New York ('NY')\n",
    "    if city == \"NY\":\n",
    "        return 20  # Return 20°C for New York\n",
    "\n",
    "    # Check if the city is Beijing ('BJ')\n",
    "    elif city == \"BJ\":\n",
    "        return 30  # Return 30°C for Beijing\n",
    "\n",
    "    # If the city is neither 'NY' nor 'BJ', return -1 to indicate unknown city\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "weather_tool = FunctionTool.from_defaults(fn=get_weather)\n",
    "multiply_tool = FunctionTool.from_defaults(fn=multiply)\n",
    "add_tool = FunctionTool.from_defaults(fn=add)\n",
    "\n",
    "agent = ReActAgent.from_tools([multiply_tool, add_tool, weather_tool], llm=llm, verbose=True)\n",
    "\n",
    "response = agent.chat(\"上海天气怎么样?，1+6*56=？\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gptac_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
