{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "# 创建 SQL Server 连接\n",
    "connection_string = (\n",
    "    \"mssql+pyodbc://sa:1@127.0.0.1/database_name?driver=ODBC+Driver+17+for+SQL+Server\"\n",
    ")\n",
    "engine = create_engine(connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from typing import Any, List\n",
    "from llama_index.core.embeddings import BaseEmbedding\n",
    "from pydantic import Field\n",
    "# 配置Embedding模型\n",
    "api_key =\"222\"\n",
    "emb_model=\"bge-m3\"\n",
    "base_url=\"http://192.168.12.10:9997/v1\"\n",
    "# emb_model =\"qwen-embedding-v1\"\n",
    "# base_url = \"http://192.168.12.10:8000/v1\"\n",
    "\n",
    "\n",
    "class OurEmbeddings(BaseEmbedding):\n",
    "    api_key: str = Field(default=api_key)\n",
    "    base_url: str = Field(default=base_url)\n",
    "    model_name: str = Field(default=emb_model)\n",
    "    client: OpenAI = Field(default=None, exclude=True)  # 显式声明 client 字段\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        api_key: str = api_key, \n",
    "        base_url: str = base_url,\n",
    "        model_name: str = emb_model,\n",
    "        **kwargs: Any,\n",
    "    ) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "        self.api_key = api_key\n",
    "        self.base_url = base_url\n",
    "        self.model_name = model_name\n",
    "        self.client = OpenAI(api_key=self.api_key, base_url=self.base_url) \n",
    "\n",
    "    def invoke_embedding(self, query: str) -> List[float]:\n",
    "        response = self.client.embeddings.create(model=self.model_name, input=[query])\n",
    "\n",
    "        # 检查响应是否成功\n",
    "        if response.data and len(response.data) > 0:\n",
    "            return response.data[0].embedding\n",
    "        else:\n",
    "            raise ValueError(\"Failed to get embedding from ZhipuAI API\")\n",
    "\n",
    "    def _get_query_embedding(self, query: str) -> List[float]:\n",
    "        return self.invoke_embedding(query)\n",
    "\n",
    "    def _get_text_embedding(self, text: str) -> List[float]:\n",
    "        return self.invoke_embedding(text)\n",
    "\n",
    "    def _get_text_embeddings(self, texts: List[str]) -> List[List[float]]:\n",
    "        return [self._get_text_embedding(text) for text in texts]\n",
    "\n",
    "    async def _aget_query_embedding(self, query: str) -> List[float]:\n",
    "        return self._get_query_embedding(query)\n",
    "\n",
    "    async def _aget_text_embedding(self, text: str) -> List[float]:\n",
    "        return self._get_text_embedding(text)\n",
    "\n",
    "    async def _aget_text_embeddings(self, texts: List[str]) -> List[List[float]]:\n",
    "        return self._get_text_embeddings(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, list)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = OurEmbeddings(api_key=api_key, base_url=base_url, model_name=emb_model)\n",
    "emb = embedding.get_text_embedding(\"你好呀呀\")\n",
    "len(emb), type(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024 <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from typing import Any, List\n",
    "from llama_index.core.embeddings import BaseEmbedding\n",
    "from pydantic import Field\n",
    "\n",
    "# 配置 Xinference 的 API 信息\n",
    "api_key = \"your_api_key\"  # 如果没有 API 密钥，可以留空\n",
    "base_url = \"http://192.168.12.10:9997/v1\"  # Xinference 服务的地址\n",
    "model_uid = \"bge-m3\"  # 替换为实际的 model_uid\n",
    "\n",
    "class XinferenceEmbeddings(BaseEmbedding):\n",
    "    api_key: str = Field(default=api_key)\n",
    "    base_url: str = Field(default=base_url)\n",
    "    model_uid: str = Field(default=model_uid)\n",
    "    client: OpenAI = Field(default=None, exclude=True)  # 显式声明 client 字段\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        api_key: str = api_key, \n",
    "        base_url: str = base_url,\n",
    "        model_uid: str = model_uid,\n",
    "        **kwargs: Any,\n",
    "    ) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "        self.api_key = api_key\n",
    "        self.base_url = base_url\n",
    "        self.model_uid = model_uid\n",
    "        self.client = OpenAI(api_key=self.api_key, base_url=self.base_url)\n",
    "\n",
    "    def invoke_embedding(self, query: str) -> List[float]:\n",
    "        try:\n",
    "            response = self.client.embeddings.create(model=self.model_uid, input=[query])\n",
    "            if response.data and len(response.data) > 0:\n",
    "                return response.data[0].embedding\n",
    "            else:\n",
    "                raise ValueError(\"Failed to get embedding from Xinference API\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            return []\n",
    "\n",
    "    def _get_query_embedding(self, query: str) -> List[float]:\n",
    "        return self.invoke_embedding(query)\n",
    "\n",
    "    def _get_text_embedding(self, text: str) -> List[float]:\n",
    "        return self.invoke_embedding(text)\n",
    "\n",
    "    def _get_text_embeddings(self, texts: List[str]) -> List[List[float]]:\n",
    "        return [self._get_text_embedding(text) for text in texts]\n",
    "\n",
    "    async def _aget_query_embedding(self, query: str) -> List[float]:\n",
    "        return self._get_query_embedding(query)\n",
    "\n",
    "    async def _aget_text_embedding(self, text: str) -> List[float]:\n",
    "        return self._get_text_embedding(text)\n",
    "\n",
    "    async def _aget_text_embeddings(self, texts: List[str]) -> List[List[float]]:\n",
    "        return self._get_text_embeddings(texts)\n",
    "\n",
    "# 测试代码\n",
    "embedding = XinferenceEmbeddings(api_key=api_key, base_url=base_url, model_uid=model_uid)\n",
    "emb = embedding.get_text_embedding(\"你好呀呀\")\n",
    "print(len(emb), type(emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, list)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "emb_model =\"bge-m3\"\n",
    "api_key =\"23231\"\n",
    "base_url=\"http://192.168.12.10:9997/v1\"\n",
    "\n",
    "\n",
    "embedding = OpenAIEmbedding(\n",
    "    api_key = api_key,\n",
    "    model = emb_model,\n",
    "    api_base = base_url # 注意这里单词不一样\n",
    ")\n",
    "\n",
    "emb = embedding.get_text_embedding(\"你好呀呀\")\n",
    "len(emb), type(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024 <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "from tenacity import retry, stop_after_attempt, wait_exponential\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "emb_model = \"bge-m3\"\n",
    "api_key = \"23231\"\n",
    "base_url = \"http://192.168.12.10:9997/v1\"\n",
    "\n",
    "@retry(stop=stop_after_attempt(5), wait=wait_exponential(multiplier=1, min=4, max=10))\n",
    "def get_embedding_with_retry(embedding, text):\n",
    "    return embedding.get_text_embedding(text)\n",
    "\n",
    "embedding = OpenAIEmbedding(\n",
    "    api_key=api_key,\n",
    "    model=emb_model,\n",
    "    api_base=base_url\n",
    ")\n",
    "\n",
    "try:\n",
    "    emb = get_embedding_with_retry(embedding, \"你好呀呀\")\n",
    "    print(len(emb), type(emb))\n",
    "except Exception as e:\n",
    "    print(f\"Failed to get embedding: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gptac_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
