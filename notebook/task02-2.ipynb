{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "\n",
    "# 加载环境变量\n",
    "load_dotenv()\n",
    "# 从环境变量中读取api_key\n",
    "api_key = os.getenv('ZISHU_API_KEY')\n",
    "base_url = \"http://43.200.7.56:8008/v1\"\n",
    "chat_model = \"glm-4-flash\"\n",
    "emb_model = \"embedding-3\"\n",
    "\n",
    "model_name = \"Qwen2.5-32B-Instruct-AWQ\"\n",
    "openai_api_base = \"http://192.168.12.10:8000/v1\"  # 本地服务地址\n",
    "\n",
    "\n",
    "# chat_model = model_name\n",
    "# base_url=openai_api_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from pydantic import Field  # 导入Field，用于Pydantic模型中定义字段的元数据\n",
    "from llama_index.core.llms import (\n",
    "    CustomLLM,\n",
    "    CompletionResponse,\n",
    "    LLMMetadata,\n",
    ")\n",
    "from llama_index.core.embeddings import BaseEmbedding\n",
    "from llama_index.core.llms.callbacks import llm_completion_callback\n",
    "from typing import List, Any, Generator\n",
    "\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "# 定义OurLLM类，继承自CustomLLM基类\n",
    "class OurLLM(CustomLLM):\n",
    "    api_key: str = Field(default=api_key)\n",
    "    base_url: str = Field(default=base_url)\n",
    "    model_name: str = Field(default=chat_model)\n",
    "    client: OpenAI = Field(default=None, exclude=True)  # 显式声明 client 字段\n",
    "\n",
    "    def __init__(self, api_key: str, base_url: str, model_name: str = chat_model, **data: Any):\n",
    "        super().__init__(**data)\n",
    "        self.api_key = api_key\n",
    "        self.base_url = base_url\n",
    "        self.model_name = model_name\n",
    "        self.client = OpenAI(api_key=self.api_key, base_url=self.base_url)  # 使用传入的api_key和base_url初始化 client 实例\n",
    "\n",
    "    @property\n",
    "    def metadata(self) -> LLMMetadata:\n",
    "        \"\"\"Get LLM metadata.\"\"\"\n",
    "        return LLMMetadata(\n",
    "            model_name=self.model_name,\n",
    "        )\n",
    "\n",
    "    @llm_completion_callback()\n",
    "    def complete(self, prompt: str, **kwargs: Any) -> CompletionResponse:\n",
    "        response = self.client.chat.completions.create(model=self.model_name, messages=[{\"role\": \"user\", \"content\": prompt}])\n",
    "        if hasattr(response, 'choices') and len(response.choices) > 0:\n",
    "            response_text = response.choices[0].message.content\n",
    "            return CompletionResponse(text=response_text)\n",
    "        else:\n",
    "            raise Exception(f\"Unexpected response format: {response}\")\n",
    "\n",
    "    @llm_completion_callback()\n",
    "    def stream_complete(\n",
    "        self, prompt: str, **kwargs: Any\n",
    "    ) -> Generator[CompletionResponse, None, None]:\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model_name,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            stream=True\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            for chunk in response:\n",
    "                chunk_message = chunk.choices[0].delta\n",
    "                if not chunk_message.content:\n",
    "                    continue\n",
    "                content = chunk_message.content\n",
    "                yield CompletionResponse(text=content, delta=content)\n",
    "\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Unexpected response format: {e}\")\n",
    "\n",
    "llm = OurLLM(api_key=api_key, base_url=base_url, model_name=chat_model)\n",
    "llmlocal = OurLLM(api_key=api_key, base_url=openai_api_base, model_name=model_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "# 创建数据库\n",
    "sqllite_path = 'llmdb.db'\n",
    "con = sqlite3.connect(sqllite_path)\n",
    "\n",
    "# 创建表\n",
    "sql = \"\"\"\n",
    "CREATE TABLE `section_stats` (\n",
    "  `部门` varchar(100) DEFAULT NULL,\n",
    "  `人数` int(11) DEFAULT NULL\n",
    ");\n",
    "\"\"\"\n",
    "c = con.cursor()\n",
    "cursor = c.execute(sql)\n",
    "c.close()\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect(sqllite_path)\n",
    "c = con.cursor()\n",
    "data = [\n",
    "    [\"专利部\",22],\n",
    "    [\"商标部\",25],\n",
    "]\n",
    "for item in data:\n",
    "    sql = \"\"\"\n",
    "    INSERT INTO section_stats (部门,人数) \n",
    "    values('%s','%d')\n",
    "    \"\"\"%(item[0],item[1])\n",
    "    c.execute(sql)\n",
    "    con.commit()\n",
    "c.close()\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.stream_complete(\"你是谁？\")\n",
    "for chunk in response:\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llmlocal.stream_complete(\"你是谁？\")\n",
    "for chunk in response:\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent import ReActAgent  \n",
    "from llama_index.core.tools import FunctionTool  \n",
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, Settings  \n",
    "from llama_index.core.tools import QueryEngineTool   \n",
    "from llama_index.core import SQLDatabase  \n",
    "from llama_index.core.query_engine import NLSQLTableQueryEngine  \n",
    "from sqlalchemy import create_engine, select  \n",
    "\n",
    "\n",
    "# 配置本地大模型  \n",
    "Settings.llm = llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from typing import Any, List\n",
    "from llama_index.core.embeddings import BaseEmbedding\n",
    "from pydantic import Field\n",
    "\n",
    "# 配置 Xinference 的 API 信息\n",
    "api_key = \"your_api_key\"  # 如果没有 API 密钥，可以留空\n",
    "base_url = \"http://192.168.12.10:9997/v1\"  # Xinference 服务的地址\n",
    "model_uid = \"bge-m3\"  # 替换为实际的 model_uid\n",
    "\n",
    "class XinferenceEmbeddings(BaseEmbedding):\n",
    "    api_key: str = Field(default=api_key)\n",
    "    base_url: str = Field(default=base_url)\n",
    "    model_uid: str = Field(default=model_uid)\n",
    "    client: OpenAI = Field(default=None, exclude=True)  # 显式声明 client 字段\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        api_key: str = api_key, \n",
    "        base_url: str = base_url,\n",
    "        model_uid: str = model_uid,\n",
    "        **kwargs: Any,\n",
    "    ) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "        self.api_key = api_key\n",
    "        self.base_url = base_url\n",
    "        self.model_uid = model_uid\n",
    "        self.client = OpenAI(api_key=self.api_key, base_url=self.base_url)\n",
    "\n",
    "    def invoke_embedding(self, query: str) -> List[float]:\n",
    "        try:\n",
    "            response = self.client.embeddings.create(model=self.model_uid, input=[query])\n",
    "            if response.data and len(response.data) > 0:\n",
    "                return response.data[0].embedding\n",
    "            else:\n",
    "                raise ValueError(\"Failed to get embedding from Xinference API\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            return []\n",
    "\n",
    "    def _get_query_embedding(self, query: str) -> List[float]:\n",
    "        return self.invoke_embedding(query)\n",
    "\n",
    "    def _get_text_embedding(self, text: str) -> List[float]:\n",
    "        return self.invoke_embedding(text)\n",
    "\n",
    "    def _get_text_embeddings(self, texts: List[str]) -> List[List[float]]:\n",
    "        return [self._get_text_embedding(text) for text in texts]\n",
    "\n",
    "    async def _aget_query_embedding(self, query: str) -> List[float]:\n",
    "        return self._get_query_embedding(query)\n",
    "\n",
    "    async def _aget_text_embedding(self, text: str) -> List[float]:\n",
    "        return self._get_text_embedding(text)\n",
    "\n",
    "    async def _aget_text_embeddings(self, texts: List[str]) -> List[List[float]]:\n",
    "        return self._get_text_embeddings(texts)\n",
    "\n",
    "# 测试代码\n",
    "embedding = XinferenceEmbeddings(api_key=api_key, base_url=base_url, model_uid=model_uid)\n",
    "emb = embedding.get_text_embedding(\"你好呀呀\")\n",
    "print(len(emb), type(emb))\n",
    "\n",
    "Settings.embed_model = embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step b01e71c1-3761-4d8f-bb85-3fec40a5338b. Step input: 请从数据库表中获取预算单位`省人力资源和社会保障厅`和`省财政厅`的支付信息，并将查询出来的支付金额（XPAY_AMT）分别汇总！\n",
      "\u001b[1;3;38;5;200mThought: The user wants to get the payment information of two budget units from a database table and summarize the payment amounts. I need to use the SJ17国库集中支付凭证表 tool to query the payment information.\n",
      "Action: SJ17国库集中支付凭证表\n",
      "Action Input: {'input': '省人力资源和社会保障厅'}\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "## 创建数据库查询引擎  \n",
    "# engine = create_engine(\"sqlite:///llmdb.db\")  \n",
    "# # prepare data  \n",
    "# sql_database = SQLDatabase(engine, include_tables=[\"section_stats\"])  \n",
    "# query_engine = NLSQLTableQueryEngine(  \n",
    "#     sql_database=sql_database,   \n",
    "#     tables=[\"section_stats\"],   \n",
    "#     llm=llmlocal ,\n",
    "#     embed_model=\"local\"   \n",
    "# )\n",
    "\n",
    "# 创建 SQL Server 连接\n",
    "connection_string = (\n",
    "    \"mssql+pymssql://sa:1@127.0.0.1:1433/甘肃省_CZBZB_2023_202403\"\n",
    ")\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "# prepare data  \n",
    "sql_database = SQLDatabase(engine, include_tables=[\"SJ17国库集中支付凭证表\"])  \n",
    "query_engine = NLSQLTableQueryEngine(  \n",
    "    sql_database=sql_database,   \n",
    "    tables=[\"SJ17国库集中支付凭证表\"],   \n",
    "    llm=llmlocal  ,\n",
    "    #embed_model=\"local\"\n",
    "    embed_model = Settings.embed_model\n",
    ")\n",
    "# 创建工具函数  \n",
    "def multiply(a: float, b: float) -> float:  \n",
    "    \"\"\"将两个数字相乘并返回乘积。\"\"\"  \n",
    "    return a * b  \n",
    "\n",
    "multiply_tool = FunctionTool.from_defaults(fn=multiply)  \n",
    "\n",
    "def add(a: float, b: float) -> float:  \n",
    "    \"\"\"将两个数字相加并返回它们的和。\"\"\"  \n",
    "    return a + b\n",
    "\n",
    "add_tool = FunctionTool.from_defaults(fn=add)\n",
    "\n",
    "def sum_payments(payments: List[float]) -> float:\n",
    "    \"\"\"汇总支付金额。\"\"\"\n",
    "    return sum(payments)\n",
    "sum_tool = FunctionTool.from_defaults(fn=sum_payments)\n",
    "\n",
    "# 把数据库查询引擎封装到工具函数对象中  \n",
    "staff_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine,\n",
    "    name=\"SJ17国库集中支付凭证表\",\n",
    "    description=\"查询预算单位的支付明细\"      \n",
    ")\n",
    "\n",
    "# 构建ReActAgent\n",
    "agent = ReActAgent.from_tools([add_tool,staff_tool,sum_tool], verbose=True)  \n",
    "# 通过agent给出指令\n",
    "# 通过 Agent 执行查询\n",
    "try:\n",
    "    response = agent.chat(\"请从数据库表中获取预算单位`省人社厅`和`省财政厅`的支付信息，并将查询出来的支付金额（XPAY_AMT）分别汇总！\")\n",
    "    print(response)\n",
    "\n",
    "    # 输出生成的 SQL 语句\n",
    "    if hasattr(response, \"extra_info\") and \"sql_query\" in response.extra_info:\n",
    "        sql_query = response.extra_info[\"sql_query\"]\n",
    "        print(\"\\nGenerated SQL Query:\")\n",
    "        print(sql_query)\n",
    "    else:\n",
    "        print(\"\\nNo SQL query found in response.\")\n",
    "except Exception as e:\n",
    "    print(f\"Query failed: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step a1d90491-85c5-423e-b465-55d3dd2db03a. Step input: 请从数据库表中获取`专利部`和`商标部`的人数，并将这两个部门的人数相加！\n",
      "\u001b[1;3;38;5;200mThought: The current language of the user is: Chinese. I need to use a tool to help me answer the question.\n",
      "Action: section_staff\n",
      "Action Input: {'input': '专利部'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: 根据查询结果，专利部共有22人。\n",
      "\u001b[0m> Running step 7c4cafe8-70dc-4570-a28e-c7bb9c3c6c06. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: I need to use the section_staff tool again to get the number of staff in the Trademark Department.\n",
      "Action: section_staff\n",
      "Action Input: {'input': '商标部'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: 商标部的当前人数是25人。\n",
      "\u001b[0m> Running step 4ff981e3-ad67-4e86-99ab-3a79f7831c6d. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: Now that I have the number of staff in the Patent Department (22) and the Trademark Department (25), I can use the add tool to calculate the total number of staff in both departments.\n",
      "Action: add\n",
      "Action Input: {'a': 22.0, 'b': 25.0}\n",
      "\u001b[0m\u001b[1;3;34mObservation: 47.0\n",
      "\u001b[0m> Running step 6f0bedea-0d91-4332-bbc3-3c8da511739e. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: 专利部和商标部的人数总和是47人。\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "## 创建数据库查询引擎  \n",
    "engine = create_engine(\"sqlite:///llmdb.db\")  \n",
    "\n",
    "# prepare data  \n",
    "sql_database = SQLDatabase(engine, include_tables=[\"section_stats\"])  \n",
    "query_engine = NLSQLTableQueryEngine(  \n",
    "    sql_database=sql_database,   \n",
    "    tables=[\"section_stats\"],   \n",
    "    llm=llmlocal ,\n",
    "    #embed_model=\"local\"\n",
    "    embed_model = Settings.embed_model\n",
    ")\n",
    "\n",
    "# 创建工具函数  \n",
    "def multiply(a: float, b: float) -> float:  \n",
    "    \"\"\"将两个数字相乘并返回乘积。\"\"\"  \n",
    "    return a * b  \n",
    "\n",
    "multiply_tool = FunctionTool.from_defaults(fn=multiply)  \n",
    "\n",
    "def add(a: float, b: float) -> float:  \n",
    "    \"\"\"将两个数字相加并返回它们的和。\"\"\"  \n",
    "    return a + b\n",
    "\n",
    "add_tool = FunctionTool.from_defaults(fn=add)\n",
    "\n",
    "# 把数据库查询引擎封装到工具函数对象中  \n",
    "staff_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine,\n",
    "    name=\"section_staff\",\n",
    "    description=\"查询部门的人数。\"  \n",
    ")\n",
    "\n",
    "# 构建ReActAgent\n",
    "agent = ReActAgent.from_tools([multiply_tool, add_tool, staff_tool], verbose=True)  \n",
    "# 通过agent给出指令\n",
    "response = agent.chat(\"请从数据库表中获取`专利部`和`商标部`的人数，并将这两个部门的人数相加！\")  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gptac_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
