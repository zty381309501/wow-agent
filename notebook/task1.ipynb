{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"http://43.200.7.56:8008/v1\"\n",
    "chat_model = \"glm-4-flash\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 加载环境变量\n",
    "load_dotenv()\n",
    "# 从环境变量中读取api_key\n",
    "api_key = os.getenv('ZISHU_API_KEY')\n",
    "base_url = \"http://43.200.7.56:8008/v1\"\n",
    "chat_model = \"glm-4-flash\"\n",
    "\n",
    "\n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI(\n",
    "    api_key = api_key,\n",
    "    base_url = base_url\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **结构化 prompt 的几个概念：**\n",
    "\n",
    "**标识符**：#, <> 等符号(-, []也是)，这两个符号依次标识标题,变量，控制内容层级，用于标识层次结构。\n",
    "\n",
    "**属性词**：Role, Profile, Initialization 等等，属性词包含语义，是对模块下内容的总结和提示，用于标识语义结构。\n",
    "\n",
    "使用分隔符清晰标示输入的不同部分,像三重引号、XML标记、节标题等分隔符可以帮助标示需要以不同方式处理的文本部分。\n",
    "\n",
    "对 GPT 模型来说，标识符标识的层级结构实现了聚拢相同语义，梳理语义的作用，降低了模型对 Prompt 的理解难度，便于模型理解 prompt 语义。\n",
    "\n",
    "属性词实现了对 prompt 内容的语义提示和归纳作用，缓解了 Prompt 中不当内容的干扰。 使用属性词与 prompt 内容相结合，实现了局部的总分结构，便于模型提纲挈领的获得 prompt 整体语义。\n",
    "\n",
    "一个好的结构化 Prompt 模板，某种意义上是构建了一个好的全局思维链。 如 LangGPT 中展示的模板设计时就考虑了如下思维链:\n",
    "\n",
    "Role (角色) -> Profile（角色简介）—> Profile 下的 skill (角色技能) -> Rules (角色要遵守的规则) -> Workflow (满足上述条件的角色的工作流程) -> Initialization (进行正式开始工作的初始化准备) -> 开始实际使用\n",
    "\n",
    "构建 Prompt 时，不妨参考优质模板的全局思维链路，熟练掌握后，完全可以对其进行增删改留调整得到一个适合自己使用的模板。例如当你需要控制输出格式，尤其是需要格式化输出时，完全可以增加 Ouput 或者 OutputFormat 这样的模块"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **prompt设计方法论**\n",
    "\n",
    "1. 数据准备。收集高质量的案例数据作为后续分析的基础。\n",
    "2. 模型选择。根据具体创作目的,选择合适的大语言模型。\n",
    "3. 提示词设计。结合案例数据,设计初版提示词;注意角色设置、背景描述、目标定义、约束条件等要点。\n",
    "4. 测试与迭代。将提示词输入 GPT 进行测试,分析结果;通过追问、深度交流、指出问题等方式与 GPT 进行交流,获取优化建议。\n",
    "5. 修正提示词。根据 GPT 提供的反馈,调整提示词的各个部分,强化有效因素,消除无效因素。\n",
    "6. 重复测试。输入经修正的提示词重新测试,比较结果,继续追问GPT并调整提示词。\n",
    "7. 循环迭代。重复上述测试-交流-修正过程,直到结果满意为止。\n",
    "8. 总结提炼。归纳提示词优化过程中获得的宝贵经验,形成设计提示词的最佳实践。\n",
    "9. 应用拓展。将掌握的方法论应用到其他创意内容的设计中,不断丰富提示词设计的技能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sys_prompt = \"\"\"你是一个聪明的客服。您将能够根据用户的问题将不同的任务分配给不同的人。您有以下业务线：\n",
    "1.用户注册。如果用户想要执行这样的操作，您应该发送一个带有\"registered workers\"的特殊令牌。并告诉用户您正在调用它。\n",
    "2.用户数据查询。如果用户想要执行这样的操作，您应该发送一个带有\"query workers\"的特殊令牌。并告诉用户您正在调用它。\n",
    "3.删除用户数据。如果用户想执行这种类型的操作，您应该发送一个带有\"delete workers\"的特殊令牌。并告诉用户您正在调用它。\n",
    "\"\"\"\n",
    "registered_prompt = \"\"\"\n",
    "您的任务是根据用户信息存储数据。您需要从用户那里获得以下信息：\n",
    "1.用户名、性别、年龄\n",
    "2.用户设置的密码\n",
    "3.用户的电子邮件地址\n",
    "如果用户没有提供此信息，您需要提示用户提供。如果用户提供了此信息，则需要将此信息存储在数据库中，并告诉用户注册成功。\n",
    "存储方法是使用SQL语句。您可以使用SQL编写插入语句，并且需要生成用户ID并将其返回给用户。\n",
    "如果用户没有新问题，您应该回复带有 \"customer service\" 的特殊令牌，以结束任务。\n",
    "\"\"\"\n",
    "query_prompt = \"\"\"\n",
    "您的任务是查询用户信息。您需要从用户那里获得以下信息：\n",
    "1.用户ID\n",
    "2.用户设置的密码\n",
    "如果用户没有提供此信息，则需要提示用户提供。如果用户提供了此信息，那么需要查询数据库。如果用户ID和密码匹配，则需要返回用户的信息。\n",
    "如果用户没有新问题，您应该回复带有 \"customer service\" 的特殊令牌，以结束任务。\n",
    "\"\"\"\n",
    "delete_prompt = \"\"\"\n",
    "您的任务是删除用户信息。您需要从用户那里获得以下信息：\n",
    "1.用户ID\n",
    "2.用户设置的密码\n",
    "3.用户的电子邮件地址\n",
    "如果用户没有提供此信息，则需要提示用户提供该信息。\n",
    "如果用户提供了这些信息，则需要查询数据库。如果用户ID和密码匹配，您需要通知用户验证码已发送到他们的电子邮件，需要进行验证。\n",
    "如果用户没有新问题，您应该回复带有 \"customer service\" 的特殊令牌，以结束任务。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#智能客服\n",
    "class SmartAssistant:\n",
    "    def __init__(self):\n",
    "        self.client = client \n",
    "\n",
    "        self.system_prompt = sys_prompt\n",
    "        self.registered_prompt = registered_prompt\n",
    "        self.query_prompt = query_prompt\n",
    "        self.delete_prompt = delete_prompt\n",
    "\n",
    "        # Using a dictionary to store different sets of messages\n",
    "        self.messages = {\n",
    "            \"system\": [{\"role\": \"system\", \"content\": self.system_prompt}],\n",
    "            \"registered\": [{\"role\": \"system\", \"content\": self.registered_prompt}],\n",
    "            \"query\": [{\"role\": \"system\", \"content\": self.query_prompt}],\n",
    "            \"delete\": [{\"role\": \"system\", \"content\": self.delete_prompt}]\n",
    "        }\n",
    "\n",
    "        # Current assignment for handling messages\n",
    "        self.current_assignment = \"system\"\n",
    "\n",
    "    def get_response(self, user_input):\n",
    "        self.messages[self.current_assignment].append({\"role\": \"user\", \"content\": user_input})\n",
    "        while True:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=chat_model,\n",
    "                messages=self.messages[self.current_assignment],\n",
    "                temperature=0.9,\n",
    "                stream=False,\n",
    "                max_tokens=2000,\n",
    "            )\n",
    "\n",
    "            ai_response = response.choices[0].message.content\n",
    "            if \"registered workers\" in ai_response:\n",
    "                self.current_assignment = \"registered\"\n",
    "                print(\"意图识别:\",ai_response)\n",
    "                print(\"switch to <registered>\")\n",
    "                self.messages[self.current_assignment].append({\"role\": \"user\", \"content\": user_input})\n",
    "            elif \"query workers\" in ai_response:\n",
    "                self.current_assignment = \"query\"\n",
    "                print(\"意图识别:\",ai_response)\n",
    "                print(\"switch to <query>\")\n",
    "                self.messages[self.current_assignment].append({\"role\": \"user\", \"content\": user_input})\n",
    "            elif \"delete workers\" in ai_response:\n",
    "                self.current_assignment = \"delete\"\n",
    "                print(\"意图识别:\",ai_response)\n",
    "                print(\"switch to <delete>\")\n",
    "                self.messages[self.current_assignment].append({\"role\": \"user\", \"content\": user_input})\n",
    "            elif \"customer service\" in ai_response:\n",
    "                print(\"意图识别:\",ai_response)\n",
    "                print(\"switch to <customer service>\")\n",
    "                self.messages[\"system\"] += self.messages[self.current_assignment]\n",
    "                self.current_assignment = \"system\"\n",
    "                return ai_response\n",
    "            else:\n",
    "                self.messages[self.current_assignment].append({\"role\": \"assistant\", \"content\": ai_response})\n",
    "                return ai_response\n",
    "\n",
    "    def start_conversation(self):\n",
    "        while True:\n",
    "            user_input = input(\"User: \")\n",
    "            if user_input.lower() in ['exit', 'quit']:\n",
    "                print(\"Exiting conversation.\")\n",
    "                break\n",
    "            response = self.get_response(user_input)\n",
    "            print(\"Assistant:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = SmartAssistant()\n",
    "assistant.start_conversation()\n",
    "\n",
    "# 运行助手\n",
    "# if __name__ == \"__main__\":\n",
    "#     assistant = SmartAssistant()\n",
    "#     assistant.start_conversation()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "\n",
    "def extract_json_content(text):\n",
    "    # 这个函数的目标是提取大模型输出内容中的json部分，并对json中的换行符、首位空白符进行删除\n",
    "    text = text.replace(\"\\n\",\"\")\n",
    "    pattern = r\"```json(.*?)```\"\n",
    "    matches = re.findall(pattern, text, re.DOTALL)\n",
    "    if matches:\n",
    "        return matches[0].strip()\n",
    "    return text\n",
    "\n",
    "class JsonOutputParser:\n",
    "    def parse(self, result):\n",
    "        # 这个函数的目标是把json字符串解析成python对象\n",
    "        # 其实这里写的这个函数性能很差，经常解析失败，有很大的优化空间\n",
    "        try:\n",
    "            result = extract_json_content(result)\n",
    "            parsed_result = json.loads(result)\n",
    "            return parsed_result\n",
    "        except json.JSONDecodeError as e:\n",
    "            raise Exception(f\"Invalid json output: {result}\") from e\n",
    "\n",
    "class GradingOpenAI:\n",
    "    def __init__(self):\n",
    "        self.model = \"glm-4-flash\"\n",
    "        self.output_parser = JsonOutputParser()\n",
    "        self.template = \"\"\"你是一位中国专利代理师考试阅卷专家，\n",
    "擅长根据给定的题目和答案为考生生成符合要求的评分和中文评语，\n",
    "并按照特定的格式输出。\n",
    "你的任务是，根据我输入的考题和答案，针对考生的作答生成评分和中文的评语，并以JSON格式返回。\n",
    "阅卷标准适当宽松一些，只要考生回答出基本的意思就应当给分。\n",
    "答案如果有数字标注，含义是考生如果答出这个知识点，这道题就会得到几分。\n",
    "生成的中文评语需要能够被json.loads()这个函数正确解析。\n",
    "生成的整个中文评语需要用英文的双引号包裹，在被包裹的字符串内部，请用中文的双引号。\n",
    "中文评语中不可以出现换行符、转义字符等等。\n",
    "\n",
    "输出格式为JSON:\n",
    "{{\n",
    "  \"llmgetscore\": 0,\n",
    "  \"llmcomments\": \"中文评语\"\n",
    "}}\n",
    "\n",
    "比较学生的回答与正确答案，\n",
    "并给出满分为10分的评分和中文评语。 \n",
    "题目：{ques_title} \n",
    "答案：{answer} \n",
    "学生的回复：{reply}\"\"\"\n",
    "\n",
    "    def create_prompt(self, ques_title, answer, reply):\n",
    "        return self.template.format(\n",
    "            ques_title=ques_title,\n",
    "            answer=answer,\n",
    "            reply=reply\n",
    "        )\n",
    "\n",
    "    def grade_answer(self, ques_title, answer, reply):\n",
    "        success = False\n",
    "        while not success:\n",
    "            # 这里是一个不得已的权宜之计\n",
    "            # 上面的json解析函数不是表现很差吗，那就多生成几遍，直到解析成功\n",
    "            # 对大模型生成的内容先解析一下，如果解析失败，就再让大模型生成一遍\n",
    "            try:\n",
    "                response = client.chat.completions.create(\n",
    "                    model=self.model,\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": \"你是一位专业的考试阅卷专家。\"},\n",
    "                        {\"role\": \"user\", \"content\": self.create_prompt(ques_title, answer, reply)}\n",
    "                    ],\n",
    "                    temperature=0.7\n",
    "                )\n",
    "\n",
    "                result = self.output_parser.parse(response.choices[0].message.content)\n",
    "                success = True\n",
    "            except Exception as e:\n",
    "                print(f\"Error occurred: {e}\")\n",
    "                continue\n",
    "\n",
    "        return result['llmgetscore'], result['llmcomments']\n",
    "\n",
    "    def run(self, input_data):\n",
    "        output = []\n",
    "        for item in input_data:\n",
    "            score, comment = self.grade_answer(\n",
    "                item['ques_title'], \n",
    "                item['answer'], \n",
    "                item['reply']\n",
    "            )\n",
    "            item['llmgetscore'] = score\n",
    "            item['llmcomments'] = comment\n",
    "            output.append(item)\n",
    "        return output\n",
    "grading_openai = GradingOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 示例输入数据\n",
    "input_data = [\n",
    " {'ques_title': '请解释共有技术特征、区别技术特征、附加技术特征、必要技术特征的含义',\n",
    "  'answer': '共有技术特征：与最接近的现有技术共有的技术特征（2.5分）； 区别技术特征：区别于最接近的现有技术的技术特征（2.5分）； 附加技术特征：对所引用的技术特征进一步限定的技术特征，增加的技术特征（2.5分）； 必要技术特征：为解决其技术问题所不可缺少的技术特征（2.5分）。',\n",
    "  'fullscore': 10,\n",
    "  'reply': '共有技术特征：与所对比的技术方案相同的技术特征\\n区别技术特征：与所对比的技术方案相区别的技术特征\\n附加技术特征：对引用的技术特征进一步限定的技术特征\\n必要技术特征：解决技术问题必须可少的技术特征'},\n",
    " {'ques_title': '请解释前序部分、特征部分、引用部分、限定部分',\n",
    "  'answer': '前序部分：独权中，主题+与最接近的现有技术共有的技术特征，在其特征在于之前（2.5分）； 特征部分：独权中，与区别于最接近的现有技术的技术特征，在其特征在于之后（2.5分）；引用部分：从权中引用的权利要求编号及主题 （2.5分）；限定部分：从权中附加技术特征（2.5分）。',\n",
    "  'fullscore': 10,\n",
    "  'reply': '前序部分：独立权利要求中与现有技术相同的技术特征\\n特征部分：独立权利要求中区别于现有技术的技术特征\\n引用部分：从属权利要求中引用其他权利要求的部分\\n限定部分：对所引用的权利要求进一步限定的技术特征'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 运行Chain\n",
    "graded_data = grading_openai.run(input_data)\n",
    "print(graded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install openai python-dotenv pydantic llama-index-embeddings-openai -i  https://pypi.tuna.tsinghua.edu.cn/simple "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip  install llama-index-core llama-index-readers-file llama-index-vector-stores-faiss  -i  https://pypi.tuna.tsinghua.edu.cn/simple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install llama-index-vector-stores-qdrant llamaindex-py-client qdrant-client requests  -i  https://pypi.tuna.tsinghua.edu.cn/simple "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install sqlalchemy pyodbc pymssql llama-index llama_index  -i  https://pypi.tuna.tsinghua.edu.cn/simple "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement faiss (from versions: none)\n",
      "ERROR: No matching distribution found for faiss\n"
     ]
    }
   ],
   "source": [
    "pip install faiss -i  https://pypi.tuna.tsinghua.edu.cn/simple "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: xinference in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (1.2.0)\n",
      "Requirement already satisfied: xinference_client in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (1.2.0)\n",
      "Requirement already satisfied: llama_index.embeddings.langchain in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (0.3.0)\n",
      "Collecting llama_index.embeddings.xinference\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/43/c2/dd9d2a38ac9fd65a3ff0fced16ca8b40a52533612ab8ec431234f8201928/llama_index_embeddings_xinference-0.2.0-py3-none-any.whl (3.2 kB)\n",
      "Requirement already satisfied: xoscar>=0.4.4 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from xinference) (0.4.6)\n",
      "Requirement already satisfied: torch in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from xinference) (2.5.1)\n",
      "Requirement already satisfied: gradio in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from xinference) (5.12.0)\n",
      "Requirement already satisfied: pillow in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from xinference) (11.1.0)\n",
      "Requirement already satisfied: click in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from xinference) (8.1.8)\n",
      "Requirement already satisfied: tqdm>=4.27 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from xinference) (4.67.1)\n",
      "Requirement already satisfied: tabulate in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from xinference) (0.9.0)\n",
      "Requirement already satisfied: requests in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from xinference) (2.32.3)\n",
      "Requirement already satisfied: pydantic in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from xinference) (2.10.4)\n",
      "Requirement already satisfied: fastapi>=0.110.3 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from xinference) (0.115.6)\n",
      "Requirement already satisfied: uvicorn in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from xinference) (0.34.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from xinference) (0.27.1)\n",
      "Requirement already satisfied: typing-extensions in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from xinference) (4.12.2)\n",
      "Requirement already satisfied: modelscope>=1.10.0 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from xinference) (1.22.2)\n",
      "Requirement already satisfied: sse-starlette>=1.6.5 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from xinference) (2.2.1)\n",
      "Requirement already satisfied: openai>=1.40.0 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from xinference) (1.58.1)\n",
      "Requirement already satisfied: python-jose[cryptography] in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from xinference) (3.3.0)\n",
      "Requirement already satisfied: passlib[bcrypt] in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from xinference) (1.7.4)\n",
      "Requirement already satisfied: aioprometheus>=23.12.0 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from aioprometheus[starlette]>=23.12.0->xinference) (23.12.0)\n",
      "Requirement already satisfied: nvidia-ml-py in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from xinference) (12.560.30)\n",
      "Requirement already satisfied: async-timeout in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from xinference) (5.0.1)\n",
      "Requirement already satisfied: peft in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from xinference) (0.14.0)\n",
      "Requirement already satisfied: timm in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from xinference) (1.0.13)\n",
      "Requirement already satisfied: setproctitle in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from xinference) (1.3.4)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.0 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from llama_index.embeddings.langchain) (0.12.10.post1)\n",
      "Requirement already satisfied: aiohttp in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from llama_index.embeddings.xinference) (3.11.11)\n",
      "Requirement already satisfied: orjson in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from aioprometheus>=23.12.0->aioprometheus[starlette]>=23.12.0->xinference) (3.10.13)\n",
      "Requirement already satisfied: quantile-python>=1.1 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from aioprometheus>=23.12.0->aioprometheus[starlette]>=23.12.0->xinference) (1.1)\n",
      "Requirement already satisfied: starlette>=0.14.2 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from aioprometheus[starlette]>=23.12.0->xinference) (0.41.3)\n",
      "Requirement already satisfied: filelock in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from huggingface-hub>=0.19.4->xinference) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from huggingface-hub>=0.19.4->xinference) (2024.12.0)\n",
      "Requirement already satisfied: packaging>=20.9 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from huggingface-hub>=0.19.4->xinference) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from huggingface-hub>=0.19.4->xinference) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama_index.embeddings.langchain) (2.0.36)\n",
      "Requirement already satisfied: dataclasses-json in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama_index.embeddings.langchain) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama_index.embeddings.langchain) (1.2.15)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama_index.embeddings.langchain) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama_index.embeddings.langchain) (1.2.0)\n",
      "Requirement already satisfied: httpx in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama_index.embeddings.langchain) (0.28.1)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama_index.embeddings.langchain) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama_index.embeddings.langchain) (3.4.2)\n",
      "Requirement already satisfied: nltk>3.8.1 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama_index.embeddings.langchain) (3.9.1)\n",
      "Requirement already satisfied: numpy in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama_index.embeddings.langchain) (2.2.1)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama_index.embeddings.langchain) (9.0.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama_index.embeddings.langchain) (0.8.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama_index.embeddings.langchain) (0.9.0)\n",
      "Requirement already satisfied: wrapt in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama_index.embeddings.langchain) (1.17.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from aiohttp->llama_index.embeddings.xinference) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from aiohttp->llama_index.embeddings.xinference) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from aiohttp->llama_index.embeddings.xinference) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from aiohttp->llama_index.embeddings.xinference) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from aiohttp->llama_index.embeddings.xinference) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from aiohttp->llama_index.embeddings.xinference) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from aiohttp->llama_index.embeddings.xinference) (1.18.3)\n",
      "Requirement already satisfied: urllib3>=1.26 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from modelscope>=1.10.0->xinference) (2.3.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from openai>=1.40.0->xinference) (4.7.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from openai>=1.40.0->xinference) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from openai>=1.40.0->xinference) (0.8.2)\n",
      "Requirement already satisfied: sniffio in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from openai>=1.40.0->xinference) (1.3.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from pydantic->xinference) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from pydantic->xinference) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from requests->xinference) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from requests->xinference) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from requests->xinference) (2024.12.14)\n",
      "Requirement already satisfied: colorama in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from tqdm>=4.27->xinference) (0.4.6)\n",
      "Requirement already satisfied: pandas>=1.0.0 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from xoscar>=0.4.4->xinference) (2.2.3)\n",
      "Requirement already satisfied: scipy>=1.0.0 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from xoscar>=0.4.4->xinference) (1.15.1)\n",
      "Requirement already satisfied: cloudpickle>=1.5.0 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from xoscar>=0.4.4->xinference) (3.1.1)\n",
      "Requirement already satisfied: psutil>=5.9.0 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from xoscar>=0.4.4->xinference) (5.9.0)\n",
      "Requirement already satisfied: tblib>=1.7.0 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from xoscar>=0.4.4->xinference) (3.0.0)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from gradio->xinference) (23.2.1)\n",
      "Requirement already satisfied: ffmpy in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from gradio->xinference) (0.5.0)\n",
      "Requirement already satisfied: gradio-client==1.5.4 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from gradio->xinference) (1.5.4)\n",
      "Requirement already satisfied: jinja2<4.0 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from gradio->xinference) (3.1.5)\n",
      "Requirement already satisfied: markupsafe~=2.0 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from gradio->xinference) (2.1.5)\n",
      "Requirement already satisfied: pydub in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from gradio->xinference) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from gradio->xinference) (0.0.20)\n",
      "Requirement already satisfied: ruff>=0.2.2 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from gradio->xinference) (0.9.1)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from gradio->xinference) (0.1.6)\n",
      "Requirement already satisfied: semantic-version~=2.0 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from gradio->xinference) (2.10.0)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from gradio->xinference) (0.13.2)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from gradio->xinference) (0.15.1)\n",
      "Requirement already satisfied: websockets<15.0,>=10.0 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from gradio-client==1.5.4->gradio->xinference) (14.1)\n",
      "Requirement already satisfied: h11>=0.8 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from uvicorn->xinference) (0.14.0)\n",
      "Requirement already satisfied: bcrypt>=3.1.0 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from passlib[bcrypt]->xinference) (4.2.1)\n",
      "Requirement already satisfied: transformers in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from peft->xinference) (4.48.0)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from peft->xinference) (1.2.1)\n",
      "Requirement already satisfied: safetensors in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from peft->xinference) (0.5.2)\n",
      "Requirement already satisfied: setuptools in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from torch->xinference) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from torch->xinference) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from sympy==1.13.1->torch->xinference) (1.3.0)\n",
      "Requirement already satisfied: ecdsa!=0.15 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from python-jose[cryptography]->xinference) (0.19.0)\n",
      "Requirement already satisfied: rsa in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from python-jose[cryptography]->xinference) (4.9)\n",
      "Requirement already satisfied: pyasn1 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from python-jose[cryptography]->xinference) (0.6.1)\n",
      "Requirement already satisfied: cryptography>=3.4.0 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from python-jose[cryptography]->xinference) (44.0.0)\n",
      "Requirement already satisfied: torchvision in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from timm->xinference) (0.20.1)\n",
      "Requirement already satisfied: cffi>=1.12 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from cryptography>=3.4.0->python-jose[cryptography]->xinference) (1.17.1)\n",
      "Requirement already satisfied: six>=1.9.0 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from ecdsa!=0.15->python-jose[cryptography]->xinference) (1.16.0)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama_index.embeddings.langchain) (1.0.7)\n",
      "Requirement already satisfied: joblib in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama_index.embeddings.langchain) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama_index.embeddings.langchain) (2024.11.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from pandas>=1.0.0->xoscar>=0.4.4->xinference) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from pandas>=1.0.0->xoscar>=0.4.4->xinference) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from pandas>=1.0.0->xoscar>=0.4.4->xinference) (2024.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama_index.embeddings.langchain) (3.1.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from typer<1.0,>=0.12->gradio->xinference) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from typer<1.0,>=0.12->gradio->xinference) (13.9.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama_index.embeddings.langchain) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama_index.embeddings.langchain) (3.23.2)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from transformers->peft->xinference) (0.21.0)\n",
      "Requirement already satisfied: pycparser in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from cffi>=1.12->cryptography>=3.4.0->python-jose[cryptography]->xinference) (2.22)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio->xinference) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio->xinference) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in d:\\programdata\\anaconda3\\envs\\gptac_venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio->xinference) (0.1.2)\n",
      "Installing collected packages: llama_index.embeddings.xinference\n",
      "Successfully installed llama_index.embeddings.xinference-0.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xinference xinference_client llama_index.embeddings.langchain  llama_index.embeddings.xinference -i  https://pypi.tuna.tsinghua.edu.cn/simple "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gptac_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
