{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "\n",
    "# 加载环境变量\n",
    "load_dotenv()\n",
    "# 从环境变量中读取api_key\n",
    "api_key = os.getenv('ZISHU_API_KEY')\n",
    "base_url = \"http://43.200.7.56:8008/v1\"\n",
    "chat_model = \"glm-4-flash\"\n",
    "emb_model = \"embedding-3\"\n",
    "\n",
    "model_name = \"Qwen2.5-32B-Instruct-AWQ\"\n",
    "openai_api_base = \"http://192.168.12.10:8000/v1\"  # 本地服务地址\n",
    "\n",
    "\n",
    "# chat_model = model_name\n",
    "# base_url=openai_api_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from pydantic import Field  # 导入Field，用于Pydantic模型中定义字段的元数据\n",
    "from llama_index.core.llms import (\n",
    "    CustomLLM,\n",
    "    CompletionResponse,\n",
    "    LLMMetadata,\n",
    ")\n",
    "from llama_index.core.embeddings import BaseEmbedding\n",
    "\n",
    "\n",
    "from llama_index.core.llms.callbacks import llm_completion_callback\n",
    "from typing import List, Any, Generator\n",
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, Settings  \n",
    "\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "# 定义OurLLM类，继承自CustomLLM基类\n",
    "class OurLLM(CustomLLM):\n",
    "    api_key: str = Field(default=api_key)\n",
    "    base_url: str = Field(default=base_url)\n",
    "    model_name: str = Field(default=chat_model)\n",
    "    client: OpenAI = Field(default=None, exclude=True)  # 显式声明 client 字段\n",
    "\n",
    "    def __init__(self, api_key: str, base_url: str, model_name: str = chat_model, **data: Any):\n",
    "        super().__init__(**data)\n",
    "        self.api_key = api_key\n",
    "        self.base_url = base_url\n",
    "        self.model_name = model_name\n",
    "        self.client = OpenAI(api_key=self.api_key, base_url=self.base_url)  # 使用传入的api_key和base_url初始化 client 实例\n",
    "\n",
    "    @property\n",
    "    def metadata(self) -> LLMMetadata:\n",
    "        \"\"\"Get LLM metadata.\"\"\"\n",
    "        return LLMMetadata(\n",
    "            model_name=self.model_name,\n",
    "        )\n",
    "\n",
    "    @llm_completion_callback()\n",
    "    def complete(self, prompt: str, **kwargs: Any) -> CompletionResponse:\n",
    "        response = self.client.chat.completions.create(model=self.model_name, messages=[{\"role\": \"user\", \"content\": prompt}])\n",
    "        if hasattr(response, 'choices') and len(response.choices) > 0:\n",
    "            response_text = response.choices[0].message.content\n",
    "            return CompletionResponse(text=response_text)\n",
    "        else:\n",
    "            raise Exception(f\"Unexpected response format: {response}\")\n",
    "\n",
    "    @llm_completion_callback()\n",
    "    def stream_complete(\n",
    "        self, prompt: str, **kwargs: Any\n",
    "    ) -> Generator[CompletionResponse, None, None]:\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model_name,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            stream=True\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            for chunk in response:\n",
    "                chunk_message = chunk.choices[0].delta\n",
    "                if not chunk_message.content:\n",
    "                    continue\n",
    "                content = chunk_message.content\n",
    "                yield CompletionResponse(text=content, delta=content)\n",
    "\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Unexpected response format: {e}\")\n",
    "\n",
    "llm = OurLLM(api_key=api_key, base_url=base_url, model_name=chat_model)\n",
    "llmlocal = OurLLM(api_key=api_key, base_url=openai_api_base, model_name=model_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试对话模型\n",
    "response = llm.complete(\"你是谁？\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试对话模型\n",
    "response = llmlocal.complete(\"你是谁？\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "emb_model =\"bge-m3\"\n",
    "api_key =\"23231\"\n",
    "base_url=\"http://192.168.12.10:9997/v1\"\n",
    "\n",
    "\n",
    "embedding = OpenAIEmbedding(\n",
    "    api_key = api_key,\n",
    "    model = emb_model,\n",
    "    api_base = base_url # 注意这里单词不一样\n",
    ")\n",
    "\n",
    "emb = embedding.get_text_embedding(\"你好呀呀\")\n",
    "Settings.embed_model = embedding\n",
    "len(emb), type(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试嵌入模型\n",
    "# 测试嵌入模型\n",
    "try:\n",
    "    emb = Settings.embed_model.get_text_embedding(\"你好呀呀\")\n",
    "    print(f\"Embedding length: {len(emb)}, Type: {type(emb)}\")\n",
    "    print(f\"Embedding vector: {emb}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从指定文件读取，输入为List\n",
    "from llama_index.core import SimpleDirectoryReader,Document\n",
    "documents = SimpleDirectoryReader(input_files=['./docs/问答手册.txt']).load_data()\n",
    "\n",
    "# 构建节点\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "transformations = [SentenceSplitter(chunk_size = 512)]\n",
    "\n",
    "from llama_index.core.ingestion.pipeline import run_transformations\n",
    "nodes = run_transformations(documents, transformations=transformations)\n",
    "\n",
    "# 构建索引\n",
    "from llama_index.vector_stores.faiss import FaissVectorStore\n",
    "import faiss\n",
    "from llama_index.core import StorageContext, VectorStoreIndex\n",
    "\n",
    "emb = embedding.get_text_embedding(\"你好呀呀\")\n",
    "vector_store = FaissVectorStore(faiss_index=faiss.IndexFlatL2(len(emb)))\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "index = VectorStoreIndex(\n",
    "    nodes = nodes,\n",
    "    storage_context=storage_context,\n",
    "    embed_model = embedding,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建检索器\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "# 想要自定义参数，可以构造参数字典\n",
    "kwargs = {'similarity_top_k': 5, 'index': index, 'dimensions': len(emb)} # 必要参数\n",
    "retriever = VectorIndexRetriever(**kwargs)\n",
    "\n",
    "# 构建合成器\n",
    "from llama_index.core.response_synthesizers  import get_response_synthesizer\n",
    "response_synthesizer = get_response_synthesizer(llm=llmlocal, streaming=True)\n",
    "\n",
    "# 构建问答引擎\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "engine = RetrieverQueryEngine(\n",
    "      retriever=retriever,\n",
    "      response_synthesizer=response_synthesizer,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提问\n",
    "question = \"审计法最早是什么时候由谁颁发的？最新的一次修改是什么时候\"\n",
    "response = engine.query(question)\n",
    "for text in response.response_gen:\n",
    "    print(text, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置查询工具\n",
    "from llama_index.core.tools import QueryEngineTool\n",
    "from llama_index.core.tools import ToolMetadata\n",
    "query_engine_tools = [\n",
    "    QueryEngineTool(\n",
    "        query_engine=engine,\n",
    "        metadata=ToolMetadata(\n",
    "            name=\"RAG工具\",\n",
    "            description=(\n",
    "                \"用于在原文中检索相关信息\"\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建ReAct Agent\n",
    "from llama_index.core.agent import ReActAgent\n",
    "agent = ReActAgent.from_tools(query_engine_tools, llm=llmlocal, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 8ecc4722-3312-4ee2-9a65-a9a5e70bd102. Step input: 审计法中对审计数据是怎么描述和授予审计机关权力的？\n",
      "\u001b[1;3;38;5;200mThought: 我需要使用RAG工具来检索审计法中对审计数据的描述以及对审计机关权力的授予内容。\n",
      "Action: RAG工具\n",
      "Action Input: {'input': '审计法中对审计数据是怎么描述和授予审计机关权力的？'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: 根据《中华人民共和国审计法》，审计机关在获取和使用审计数据方面拥有以下权力和相关规定：\n",
      "\n",
      "1. **数据提供权限**：审计机关有权要求被审计单位按其规定提供财务、会计资料以及与财政收支、财务收支有关的业务、管理等资料，包括电子数据和有关文档。被审计单位不得拒绝、拖延、谎报。同时，被审计单位负责人应对所提供资料的及时性、真实性和完整性负责（见第三十四条）。\n",
      "\n",
      "2. **数据获取方式**：国家政务信息系统和数据共享平台应当按照规定向审计机关开放。如果审计机关通过这些系统和平台取得的电子数据等资料能够满足其需要，那么审计机关不得要求被审计单位重复提供这些资料（见第三十五条）。\n",
      "\n",
      "3. **数据分析与核实**：审计机关对取得的电子数据等资料进行综合分析，如果需要向被审计单位核实有关情况，被审计单位应当予以配合（见第三十四条）。\n",
      "\n",
      "这些规定确保了审计机关能够有效获取和使用必要的数据，以履行审计职责。\n",
      "\u001b[0m> Running step 3d3718f3-5811-4183-8907-bef5a948ef3a. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: 我可以回答用户的问题，不需要使用更多工具。\n",
      "Answer: 根据《中华人民共和国审计法》，审计机关在获取和使用审计数据方面有以下权力和相关规定：\n",
      "\n",
      "1. **数据提供权限**：审计机关有权要求被审计单位提供财务、会计资料以及与财政收支、财务收支有关的业务、管理等资料，包括电子数据和有关文档。被审计单位不得拒绝、拖延或谎报，其负责人应对所提供资料的及时性、真实性和完整性负责。\n",
      "\n",
      "2. **数据获取方式**：国家政务信息系统和数据共享平台应当按规定向审计机关开放。如果审计机关通过这些系统和平台取得的电子数据等资料能够满足其需要，那么审计机关不得要求被审计单位重复提供这些资料。\n",
      "\n",
      "3. **数据分析与核实**：审计机关对取得的电子数据等资料进行综合分析，如果需要向被审计单位核实有关情况，被审计单位应当予以配合。\n",
      "\n",
      "这些规定确保了审计机关能够有效获取和使用必要的数据，以履行审计职责。\n",
      "\u001b[0m根据《中华人民共和国审计法》，审计机关在获取和使用审计数据方面有以下权力和相关规定：\n",
      "\n",
      "1. **数据提供权限**：审计机关有权要求被审计单位提供财务、会计资料以及与财政收支、财务收支有关的业务、管理等资料，包括电子数据和有关文档。被审计单位不得拒绝、拖延或谎报，其负责人应对所提供资料的及时性、真实性和完整性负责。\n",
      "\n",
      "2. **数据获取方式**：国家政务信息系统和数据共享平台应当按规定向审计机关开放。如果审计机关通过这些系统和平台取得的电子数据等资料能够满足其需要，那么审计机关不得要求被审计单位重复提供这些资料。\n",
      "\n",
      "3. **数据分析与核实**：审计机关对取得的电子数据等资料进行综合分析，如果需要向被审计单位核实有关情况，被审计单位应当予以配合。\n",
      "\n",
      "这些规定确保了审计机关能够有效获取和使用必要的数据，以履行审计职责。\n"
     ]
    }
   ],
   "source": [
    "# 让Agent完成任务\n",
    "# response = agent.chat(\"请问商标注册需要提供哪些文件？\")\n",
    "response = agent.chat(\"审计法中对审计数据是怎么描述和授予审计机关权力的？\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gptac_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
